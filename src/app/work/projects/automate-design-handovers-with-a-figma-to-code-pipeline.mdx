---
title: "Aerial Mapping Drone"
publishedAt: "2024-04-15"
summary: "An platform that generates real-time, high-fidelity 3D reconstructions of interiors and outdoors by combining advanced neural rendering with GPU-accelerated visualization."
images:
  - "/images/projects/aerial-drone/cover-01.jpg"
  - "/images/projects/aerial-drone/cover-02.jpg"
  - "/images/projects/aerial-drone/cover-03.jpg"
  - "/images/projects/aerial-drone/cover-04.jpg"
team:
  - name: "Gautam Gupta"
    role: "Lead Developer"
    avatar: "/images/avatar.jpg"
    linkedIn: "https://www.linkedin.com/in/gautam-gupta-382720175"
---

## Overview

The Aerial Mapping Drone project delivers an end-to-end pipeline for capturing, processing, and visualizing subterranean environments. Equipped with high-resolution cameras and inertial sensors, the drone flies through tunnels to acquire time-stamped imagery. Downstream, we apply a 4D Gaussian Splatting neural renderer—augmented by a lightweight deformation network—to reconstruct detailed geometric and texture information in real time, enabling rapid assessment of structural integrity.

## Key Features

- **4D Neural Representation**  
  Implements a hybrid spatio-temporal encoding using 4D Gaussian primitives and an MLP-based deformation predictor to capture both static geometry and dynamic viewpoint changes.

- **CUDA-Accelerated Rendering**  
  Leverages custom CUDA kernels to drive an interactive renderer at 800×800 resolution and 72 FPS, ensuring smooth exploration of large tunnel segments.

- **Automated Fidelity Benchmarking**  
  Integrates PSNR, SSIM, and LPIPS metrics into the pipeline to quantitatively evaluate reconstruction quality against ground-truth scans.

- **Complete Vision Stack**  
  Uses Python, PyTorch, TensorFlow, and OpenCV for data ingestion, neural network training, and pre-/post-processing of imagery.

## Technologies Used

- **Python & OpenCV** for image capture, preprocessing, and calibration  
- **PyTorch & TensorFlow** for designing and training the 4D Gaussian Splatting and deformation MLP modules  
- **CUDA** for writing custom kernels that accelerate both neural inference and rendering loops  
- **Matplotlib & Graphviz** for offline visualization of reconstruction error maps and call-flow diagrams  
- **GitHub Actions** to automate nightly builds, tests, and performance benchmarks  

## Challenges and Learnings

Balancing real-time performance with photorealistic quality was the primary challenge. We mitigated token-limit–style constraints in neural rendering by developing a sparse Gaussian memory that selectively refines only the most perceptually important regions. Additionally, integrating multi-sensor fusion (camera+IMU) required careful synchronization and distortion correction to prevent artifacts in the 4D splatting stage.

## Outcome

The prototype system successfully generated live 3D tunnel maps during field trials, reducing post-processing time by 70% and achieving an average PSNR of 32 dB, SSIM of 0.89, and LPIPS of 0.12 on benchmark datasets. This demonstrates its potential for infrastructure inspection, search-and-rescue planning, and digital-twin creation in challenging environments.
